# Universal-Transformer-Pytorch
Implementation of Universal Transformer in Pytorch. 

## Universal Transformer 
The basic transformer implementation has been taken from [https://github.com/kolloldas/torchnlp](https://github.com/kolloldas/torchnlp). For now has been implemented:

- Universal Encoder Decoder, with position and time embeddings.
- Universal Transformer for bAbI data.  

## How to run
```
python main.py --task 1
```

## TODO
- APT (Hopefully by this week will be ready)
- Modularize the code in different files
- Run task 1-20 and report performance
